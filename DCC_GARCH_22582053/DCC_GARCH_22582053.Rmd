---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "MV-Volatility modeling applied to local equities"
#subtitle: "This will appear as Right Header"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Some Guy}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Austin Byrne"  # First Author - note the thanks message displayed as an italic footnote of first page.
Ref1: "Stellenbosch University" # First Author's Affiliation
Email1: "22582053\\@sun.ac.za" # First Author's Email address

#Author2: "John Smith"
#Ref2: "Some other Institution, Cape Town, South Africa"
#Email2: "John\\@gmail.com"
#CommonAffiliation_12: TRUE # If Author 1 and 2 have a common affiliation. Works with _13, _23, etc.

#Author3: "John Doe"
#Email3: "Joe\\@gmail.com"

CorrespAuthor_1: TRUE  # If corresponding author is author 3, e.g., use CorrespAuthor_3: TRUE

# Comment out below to remove both. JEL Codes only given if keywords also given.
#keywords: "Multivariate GARCH \\sep Kalman Filter \\sep Copula" # Use \\sep to separate
#JELCodes: "L250 \\sep L100"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 12pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
abstract: |
  The main aim of this study is to evaluate the volatility structure of local equities. This analysis will be achieved by making use of DCC-GARCH multivariate volatility model. Through this analysis I indetify the most volatile index/sector to be the Resource sector, while the ALSI and Industrial sector to hold the lowest volatility. 
---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')
# Note: Include = FALSE implies the code is executed, but not printed in your pdf.
# warning and message = FALSE implies ugly messages and warnings are removed from your pdf.
# These should be picked up when you execute the command chunks (code sections below) in your rmd, not printed in your paper!

# Lets load in example data, and see how this can be stored and later called from your 'data' folder.
if(!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)
library(MTS)
library(robustbase)
library(gt)
library(dplyr)
library(lubridate)
library(zoo)
library(tidyr)
library(tseries)
library(PortfolioAnalytics)
library(ggplot2)
library(RcppRoll)
library(tbl2xts)
library(fmxdat)
library(rmsfuns)
library(PerformanceAnalytics)
list.files('code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))


```

```{r}
#Loading the relevant data
LCL_Indices <- readRDS("C:/Users/austi/OneDrive/Desktop/Masters/Financial Econometrics/Project/DCC_GARCH_volatility_model/data/LCL_Indices (1).rds")
#LCL_Stock_Returns <- readRDS("C:/Users/austi/OneDrive/Desktop/Masters/Financial Econometrics/Project/DCC_GARCH_volatility_model/data/LCL_Stock_Returns (1).rds")
```

```{r, include=FALSE}
#Checking how many total observations we have
nrow(LCL_Indices)

# For LCL_Indices data set
sum(is.na(LCL_Indices))

# For LCL_Stock_Returns data set
#sum(is.na(LCL_Stock_Returns))
```

```{r, include=FALSE}
#Creating a new cleaned data set that has no NA's 
LCL_Indices_Cleaned <- na.omit(LCL_Indices)

#Evaluating whether the NA's have been removed successfully
sum(is.na(LCL_Indices_Cleaned))

#Evaluating the amount of data still available
nrow(LCL_Indices_Cleaned)
```


```{r}
# Reshaping the LCL_Indices_Cleaned data to a wide format
LCL_Indices_wide <- LCL_Indices_Cleaned %>%
  select(date, Name, Returns) %>%
  spread(Name, Returns)

```

```{r}
# Calculating the correlation matrix for index returns
cor_matrix <- cor(LCL_Indices_wide[,-1], use = "complete.obs")

```

```{r}
# Setting a threshold for identifying high correlations
high_corr_threshold <- 0.9

# Finding index pairs with correlations above the threshold
high_corr_indices <- which(abs(cor_matrix) > high_corr_threshold, arr.ind = TRUE)

# Excluding self-correlation (diagonal elements)
high_corr_indices <- high_corr_indices[high_corr_indices[, 1] != high_corr_indices[, 2], ]

# Ensuring unique pairs are identified to avoid duplication
unique_high_corr_indices <- unique(t(apply(high_corr_indices, 1, sort)))

# Associating the indices names with the high correlation pairs
high_corr_pairs <- apply(unique_high_corr_indices, 1, function(idx) {
  return(colnames(cor_matrix)[idx])
})

```

```{r}
# Define the indices to include in the analysis
selected_indices <- c("ALSI", "Financials", "Industrials", "jsapy", "Resources")

# Filter the dataset to keep only the selected indices
LCL_Indices_Selected <- LCL_Indices_Cleaned %>%
  filter(Name %in% selected_indices)
```


<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->

# Introduction \label{Introduction}

When dealing with financial markets and portfolio creation it is paramount for an investor or risk managers to understand the risk involved in their investment decisions. Within financial markets, volatility is often evaluated as a measure of uncertainty and risk. Thus, through evaluating the volatility structure of indexes we are able to understand the risk structure involved with certain investment decisions. Furthermore, by evaluating the dynamic correlations between indexes we are able to better diversify a portfolio and reduce risk. The main objective of this project is to understand the multivariate volatility structure of local equities and thus understand the relative risk associated with certain investment decisions. 

The use of Dynamic Conditional Correlation (DCC) GARCH models to evaluate market dynamics and dynamic correlations has become more frequent in portfolio creation and financial theory. @boudt2013robust make use of an extension of a DCC GARCH model to forecasting the covariance matrix of the daily EUR/USD and Yen/USD return series [@boudt2013robust]. Additionally, @shiferaw2019time run a multivariate DCC-GARCH model to evaluate time varying correlation between energy price dynamics and agricultural commodity to name a few [@shiferaw2019time]. 

Understanding this topic can be vitally important for investors and portfolio managers when making investment decisions. Realizing the risk exposure a portfolio is inherently exposed to is crucial when making investment decisions. Thus, by modeling the volatility of local equities an investor can make more informed investment decisions based on the intended level of risk the investors wants to take on. This project aims to achieve this analysis through a Dynamic Conditional Correlation (DCC) GARCH model capturing the market dynamics and volatility structures of local sectors and indexes. This model is renowned for its proficiency in assessing multivariate time series data, particularly its capability to capture the evolving correlations between different financial time series. 

The results of this study find the Resource sector to be the most volatile with the ALSI and Industrial sector being the least volatile. 

The remainder of this paper is ordered as follows: The next section covers the Data and Methodology, followed by the Results section, followed by the discussion section and lastly the Conclusion. 



# Data Methodology \label{Data Methodology}

Throughout this paper multivariate volatility modeling techniques will be used with the focus on understanding the dynamic relationships and co-movements of volatility across multiple sectors/indexes within the local equities market. 

Of the MV-volatility modeling techniques that there are available, I will be utilizing the DCC-GARCH model. My aim is to use DCC models in the multivariate volatility analysis as these models are simpler and relax the constraint of a fixed correlation structure which is assumed by the CCC model, which allows for estimates of time varying correlation. I will be conducting the DCC-GARCH volatility model in R statistical package. 

The data I am using holds the returns for the following indexes/sectors, ALSI, Financial Sector, Industrial Sector, jsapy index and the Resource Sector.

## Variation in index returns 

Figure \ref{Figure1} below plots the time series analysis of each indexes returns. The importance of this plot for this analysis lies in it's ability to portray the variance structure in each indexes returns. By visualizing the return structure of an index through time we are able to identify the most volatile and thus more risky indexes. 

While holding the y-axis fixed, figure \ref{Figure1} shows that the most volatile index/sector is that of the Resource sector.  While the ALSI and Industrial sector appear to be the least volatile and thus lowest risk investment opportunities. 

To further evaluate the return structure of the indexes/sectors in question figure \ref{Figure2} analyses the distribution of returns through a histogram plot. 

```{r Figure1,  warning =  FALSE, fig.align = 'center', fig.cap = "Time Series Analysis of Returns \\label{Figure1}", fig.ext = 'png', fig.height = 5, fig.width = 6}

# Using ggplot2 to create time series plots of the selected indices' returns
Index_return_plot <- ggplot(LCL_Indices_Selected, aes(x = date, y = Returns, color = Name)) + 
  geom_line() + 
  facet_wrap(~Name, scales = "fixed") +  # Ensures comparable y-axis scales across facets
  theme_minimal() +
  ggtitle("Time Series Plot of Indices Returns with Fixed Y-Axis")

# Displaying the plot
Index_return_plot


```

## Analyzing the Distribution of Returns

Through figure \ref{Figure1} we have identified the resource sector as the most volatile and thus most risky investment option, while the ALSI and industrial sector to be the least volatile. To build on this analysis I run a histogram plot of the return structure. Through this plot we are able to identify any fat tails or skewness in returns as well as identify the index/sector with the widest variation in returns. 

The results of figure \ref{Figure2} below are inline with that found in figure \ref{Figure1} above. The resource sector once again appears to be the most volatile with the ALSI and industrial sector appearing to be the least volatile. 

Following the analysis of figures \ref{Figure1} and \ref{Figure2} we have now obtained a better understanding of the return structure and volatility of the indexes/sectors in question. Thus, we are now able to proceed to the multivariate volatility analysis using the DCC-GARCH model. However, Before I fit any GARCH models to my data I need evaluate the presence of any ARCH effects. If there are no ARCH effects present, it does not make sense to run any GARCH models for this volatility analysis. To test for ARCH effects I perform the McLeod-Li test. This test checks for auto regressive conditional heteroskedasticity (ARCH) in the time series data [@wang2005testing]. If present the p-values will be very close to 0, indicating that the volatility within the variables changes over time. Thus, it is viable to use GARCH models. This test is done in the next section.  

```{r Figure2,  warning =  FALSE, fig.align = 'center', fig.cap = "Distribution of Returns \\label{Figure2}", fig.ext = 'png', fig.height = 5, fig.width = 6}

# Creating histograms for the distribution of returns for each index
Return_distribution_hist <- ggplot(LCL_Indices_Selected, aes(x = Returns, fill = Name)) + 
  geom_histogram(bins = 30, color = "black") +
  facet_wrap(~Name, scales = "fixed") +  # Fixed scales for x-axis across facets
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +  # Tilting x-axis labels for readability
  ggtitle("Distribution of Returns for Indices with Fixed X-Axis")

Return_distribution_hist

```


## Testing for ARCH Effects

The results in table 2.1 below provide evidence of ARCH effects. All p-values are close to zero which indicates that there is statistical significance indicating that the volatility between the variables change over time. Thus, it is viable to make use of a GARCH model to conduct the volatility analysis. 

In the next section I will make use of the DCC-GARCH model to plot the Dynamic Conditional Correlation plots and report the results. 


```{r}
# Calculating the date range for each index
date_ranges <- LCL_Indices_Selected %>%
  group_by(Name) %>%
  summarize(Start_Date = min(date, na.rm = TRUE),
            End_Date = max(date, na.rm = TRUE))
```

```{r}
# Defining a consistent time range for the analysis
start_date <- as.Date("2002-02-28")  # Start date
end_date <- as.Date("2023-11-30")    # End date

# Filtering the data set for the defined time range
LCL_Indices_Filtered <- LCL_Indices_Selected %>%
  filter(date >= start_date & date <= end_date)

```

```{r}
# Loading necessary libraries
pacman::p_load("tbl2xts", "MTS")

# Converting the filtered dataset to an xts object for time series analysis
xts_rtn <- LCL_Indices_Filtered %>% tbl_xts(., cols_to_xts = "Returns", spread_by = "Name")
```


```{r ,results='hide'}
# Performing the McLeod-Li test to check for ARCH effects
MarchTest(xts_rtn)
```

```{r}

test_results <- data.frame(
  Test = c("Q(m) of squared series (LM test)", 
           "Rank-based Test", 
           "Q_k(m) of squared series", 
           "Robust Test (5%)"),
  TestStatistic = c(44.88386, 108.2555, 341.5009, 321.4297),
  PValue = c(2.282185e-06, 0, 0.000104816, 0.001529345)
)

# Using knitr to create a LaTeX formatted table
knitr::kable(test_results, format = "latex", booktabs = TRUE,
             caption = "McLeod-Li Test Results for Autoregressive Conditional Heteroskedasticity")

```

# Results \label{Results}

In the following section I plot a volatility comparison plot with the purpose of further understanding which index/sector inherently is exposed to the most volatility. Furthermore, I run the Dynamic Conditional Correlation plots for each index/sector. 

## Volatility Comparisson

Figure \ref{Figure3} below represents the volatility comparison plot. Through evaluating this plot it is once again evident that the resources sector is consistently the most volatile index/sector. Furthermore, post 2020 their is a significant spike in the volatility in the Financials sector and the jsapy, thus suggesting the Financials Sector and jsapy index are the most sensitive to large shocks in the economy, such as the COVID-19 pandemic. Additionally, the Industrial sector remains the least volatile along with the ALSI. 

Now that I have further strengthened my understanding of the nature of volatility for each index/sector, I will now focus my analysis on the conditional correlations in the next section. 

```{r, results='hide'}
# Loading the rmgarch library for advanced GARCH modeling
library(rmgarch)

# Preprocessing the data using dccPre function from rmgarch
# This includes specifying that the mean of each series is included in the model (include.mean = TRUE)
# and setting the autoregressive order for the mean equation to zero (p = 0)
DCCPre <- dccPre(xts_rtn, include.mean = TRUE, p = 0) 
```




```{r}
# Loading necessary library
pacman::p_load("zoo")

# Extracting the marginal volatilities from the DCC preprocessing output
Vol <- DCCPre$marVol
colnames(Vol) <- colnames(xts_rtn)

# Converting to a data frame and adding the date column back
Vol <- data.frame(cbind(date = index(xts_rtn), Vol)) %>%
  mutate(date = as.Date(date)) %>%  # Convert to Date format
  tbl_df()

# Reshaping the data for plotting
TidyVol <- Vol %>% gather(Indexes, Sigma, -date)

```

```{r Figure3,  warning =  FALSE, fig.align = 'center', fig.cap = "Volatility comparisson plot \\label{Figure3}", fig.ext = 'png', fig.height = 5, fig.width = 6}
# Creating the volatility comparison plot
Volatility_Comparison_Plot <- ggplot(TidyVol, aes(x = date, y = Sigma, colour = Indexes)) +
  geom_line() +
  theme_minimal() +
  ggtitle("Volatility Comparison Plot")  # Adding a title to the plot

# Displaying the plot
print(Volatility_Comparison_Plot)
```

```{r, results='hide'}
#Prepairning for the DCC model fitting 
# Extracting standardized residuals from the DCC preprocessing output
StdRes <- DCCPre$sresi

# Detaching packages no longer needed
detach("package:tidyverse", unload=TRUE)
detach("package:tbl2xts", unload=TRUE)

# Fitting the DCC model to the standardized residuals
DCC <- dccFit(StdRes, type="Engle")
```


```{r}
# Reloading tidyverse, tbl2xts, and broom packages
pacman::p_load("tidyverse", "tbl2xts", "broom")

```

```{r, results='hide'}
# Extracting time-varying correlations from the DCC model
Rhot <- DCC$rho.t

# Function to rename and reformat the DCC correlations for visualization
renamingdcc <- function(ReturnSeries, DCC.TV.Cor) {
    ncolrtn <- ncol(ReturnSeries)
    namesrtn <- colnames(ReturnSeries)

    nam <- c()
    xx <- mapply(rep, times = ncolrtn:1, x = namesrtn)

    for (j in 1:(ncolrtn)) {
        for (i in 1:(ncolrtn)) {
            nam[(i + (j-1)*(ncolrtn))] <- paste(xx[[j]][1], xx[[i]][1], sep="_")
        }
    }

    colnames(DCC.TV.Cor) <- nam
    DCC.TV.Cor <- data.frame(cbind(date = index(ReturnSeries), DCC.TV.Cor)) %>%
        mutate(date = as.Date(date)) %>% tbl_df()
    DCC.TV.Cor <- DCC.TV.Cor %>% gather(Pairs, Rho, -date)

    return(DCC.TV.Cor)
}

# Applying the renaming function to the DCC correlations
Rhot <- renamingdcc(ReturnSeries = xts_rtn, DCC.TV.Cor = Rhot)

# Displaying the first few rows of the processed correlations
head(Rhot %>% arrange(date))

```

## Dynamic Conditional Correlations

In this section I plot the Dynamic Conditional Correlation plots for each index/sector. Through these plots we are able to identify which index's/sectors are correlated over time. This is important information when creating optimal portfolios, ensuring diversification and reducing risk for portfolio managers and investors alike. 

Figure \ref{Figure4} represents the Dynamic Conditional Correlations plot for both the Resources sector and jsapy index. Figure \ref{Figure5} represents the Dynamic Conditional Correlations plot for the Financial and Industrial sector. Lastly, Figure \ref{Figure6} represents the Dynamic Conditional Correlations plot for the ALSI. 

Figure \ref{Figure4} illustrates the Resource sector has a high dynamic correlation with the ALSI with a correlation above 0.5 throughout the entire time frame. Furthermore, the Resources sector has the lowest dynamic correlation with the jsapy index. Additionally, Figure \ref{Figure4} illustrates that the jsapy index has a high dynamic correlation with the Financial sector and lowest dynamic correlation with the Resource sector. 

Figure \ref{Figure5} illustrates that the Financial sector holds a high dynamic correlation with the jsapy index, ALSI and the Industrial sector. While holding a low dynamic correlation with the Resource sector. Furthermore, Figure \ref{Figure5} illustrates that the Industrial Sector holds a strong dynamic correlation with the ALSI and holds its lowest dynamic correlation with the Resource sector and jsapy. 

Lastly, Figure\ref{Figure6} illustrates that the ALSI holds a strong dynamic correlation with the Industrial and Resource sector while holding its lowest dynamic correlation with the jsapy index. 

```{r}
pacman::p_load(ggthemes)

# Creating a plot for the dynamic correlations of ALSI with other indices
g1 <- ggplot(Rhot %>% filter(grepl("ALSI_", Pairs), !grepl("_ALSI", Pairs))) + 
  geom_line(aes(x = date, y = Rho, colour = Pairs)) + 
  theme_hc() +
  ggtitle("Dynamic Conditional Correlations: ALSI")


```

```{r}

# Creating a plot for the dynamic correlations of Financials with other indices
g2 <- ggplot(Rhot %>% filter(grepl("Financials_", Pairs), !grepl("_Financials", Pairs))) + 
  geom_line(aes(x = date, y = Rho, colour = Pairs)) + 
  theme_hc() +
  ggtitle("Dynamic Conditional Correlations: Financials")


```

```{r}
# Creating a plot for the dynamic correlations of Industrials with other indices
g3 <- ggplot(Rhot %>% filter(grepl("Industrials_", Pairs), !grepl("_Industrials", Pairs))) + 
  geom_line(aes(x = date, y = Rho, colour = Pairs)) + 
  theme_hc() +
  ggtitle("Dynamic Conditional Correlations: Industrials")

```


```{r}
# Creating a plot for the dynamic correlations of Resources with other indices
g4 <- ggplot(Rhot %>% filter(grepl("Resources_", Pairs), !grepl("_Resources", Pairs))) + 
  geom_line(aes(x = date, y = Rho, colour = Pairs)) + 
  theme_hc() +
  ggtitle("Dynamic Conditional Correlations: Resources")

```


```{r}
# Creating a plot for the dynamic correlations of jsapy with other indices
g5 <- ggplot(Rhot %>% filter(grepl("jsapy_", Pairs), !grepl("_jsapy", Pairs))) + 
  geom_line(aes(x = date, y = Rho, colour = Pairs)) + 
  theme_hc() +
  ggtitle("Dynamic Conditional Correlations: jsapy")
```

```{r Figure4,  warning =  FALSE, fig.align = 'center', fig.cap = "Dynamic Conditional Correlations: Resources and jsapy \\label{Figure4}", fig.ext = 'png', fig.height = 5, fig.width = 6}
pacman::p_load(patchwork)

combined_plot_1 <- g4 + g5 +
  plot_layout(ncol = 1, nrow = 2)  


print(combined_plot_1)

```

```{r Figure5,  warning =  FALSE, fig.align = 'center', fig.cap = "Dynamic Conditional Correlations: Financials and Industrials \\label{Figure5}", fig.ext = 'png', fig.height = 5, fig.width = 6}
combined_plot_2 <- g2 + g3 +
  plot_layout(ncol = 1, nrow = 2)

print(combined_plot_2)
```

```{r Figure6,  warning =  FALSE, fig.align = 'center', fig.cap = "Dynamic Conditional Correlations: ALSI \\label{Figure6}", fig.ext = 'png', fig.height =3, fig.width = 6}
combined_plot_3 <- g1 +
  plot_layout(ncol = 1, nrow = 1)

print(combined_plot_3)
```



# Discussion \label{Discussion}

In the above analysis I have evaluated the overall volatility of each index/sector and compared the results with each other. Furthermore, I have evaluated the dynamic correlations between each index/sector. With these results one can identify which indexes/sector hold the highest risk and which indexes/sectors to combine in a portfolio to induce diversification and risk mitigation. 

Through my analysis it is evident that the Resource sector holds the highest volatility and thus highest risk while the ALSI and Industrial sector hold the lowest volatility and thus lowest source of risk. Thus if you were attempting to build a low risk portfolio you would hold a high proportion of the ALSI and Industrial sector. If this were the case and you intended to impose some diversification into your portfolio we could evaluate the Dynamic Conditional Correlation plots for the ALSI and Industrial sector. 

With respect to the ALSI investing in the jsapy index would provide for increased diversification in your portfolio. This addition to the portfolio could be warranted as the jsapy index holds average volatility and thus average risk. Therefore, by introducing the jsapy to the portfolio we are increasing the diversification while not exposing the portfolio to a great deal of risk. With respect to the Industrial Sector investing in the Resource sector would induce diversification although increasing risk through the highly volatile Resource Sector. 

Therefore, a portfolio that holds a large portion in the ALSI and Industrial sector with slight investment in the jsapy and even slighter investment in the Resource sector will provide for a low risk, diversified investment portfolio. 




# Conclusion \label{Conclusion}

To conclude, throughout this study I evaluate the return structure and volatility of the ALSI, Financial Sector, Industrial Sector, jsapy index and the Resource Sector. Furthermore, by making use of the DCC-GARCH volatility model I was able to establish the dynamic conditional correlation for each index/sector in question. 

The results found the Resource sector to be the most volatile and thus most risky while finding the ALSI and Industrial sector to be the least volatile and thus lowest risk options of the available indexes/sectors. Through evaluating the respective dynamic correlations it is found that the most optimal portfolio construction could potentially be, a portfolio that holds a large portion in the ALSI and Industrial sector with slight investment in the jsapy and even slighter investment in the Resource sector as this portfolio would induce a low risk and well diversified portfolio. 

The limitations to the study are that we only focus on the ALSI, Financial Sector, Industrial Sector, jsapy index and the Resource Sector, thus the results are only limited to these indexes/sectors. 



<!-- Make title of bibliography here: -->
<!-- \newpage -->

\newpage

# References {-}

<div id="refs"></div>




